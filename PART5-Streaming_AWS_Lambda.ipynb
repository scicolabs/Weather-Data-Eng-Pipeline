{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/futur.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 5 -Serverless Architecture with Amazon Lambda\n",
    "段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火段火\n",
    "### The Vision\n",
    "**As Data Sciensits, What don't we just let Amazon (or any other cloud services) deal with the data pipes, so we can spend more time focusing on what we're good at.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is AWS Lambda?\n",
    "位\n",
    "**AWS Lambda** is a compute service where you can upload your code to AWS Lambda and the service can run the code on your behalf using AWS infrastructure. After you upload your code and create a Lambda function, **AWS Lambda** takes care of provisioning and managing the servers that you use to run the code.\n",
    "\n",
    "**AWS Lambda** runs your code on a high-availability compute infrastructure and performs all of the administration of the compute resources, including server and operating system maintenance, capacity provisioning and automatic scaling, code monitoring and logging. **All you need to do is supply your code!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/lambdaSNS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Amazon Simple Notification Service?\n",
    "**Amazon Simple Notification Service (Amazon SNS)** is a web service that coordinates and manages the delivery or sending of messages to subscribing endpoints or clients. In Amazon SNS, there are two types of clientspublishers and subscribersalso referred to as producers and consumers. Publishers communicate asynchronously with subscribers by producing and sending a message to a topic, which is a logical access point and communication channel. Subscribers (i.e., web servers, email addresses, Amazon SQS queues, AWS Lambda functions) consume or receive the message or notification over one of the supported protocols (i.e., Amazon SQS, HTTP/S, email, SMS, Lambda) when they are subscribed to the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/sns.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application Flow Summary\n",
    "1. One of the 160 NEXRAD radars uploads an object to the source bucket in Amazon S3 (object-created event).\n",
    "2. Amazon S3 detects the object-created event.\n",
    "3. Amazon S3 publishes the s3:ObjectCreated:* event to AWS Lambda by invoking the Lambda function and passing event data as a function parameter.\n",
    "4. AWS Lambda executes the Lambda function by assuming the execution role that you specified at the time you created the Lambda function.\n",
    "5. From the event data it receives, the Lambda function knows the source bucket name and object key name. The Lambda function runs and saves the output to the target bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/s3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources Needed for Lambda Implementation\n",
    "\n",
    "- AWS account with admin privileges\n",
    "- Source and target S3 Bucket\n",
    "- Lambda function (your code)\n",
    "- Zip file of library dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/resources.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Function: The only code you have to write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "from utils import processData\n",
    "\n",
    "print('Loading function')\n",
    "\n",
    "s3c = boto3.client('s3')\n",
    "s3r = boto3.resource('s3')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    # Get NEXRAD data from it's S3 bucket\n",
    "    bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    key = event['Records'][0]['s3']['object']['key']\n",
    "    \n",
    "    keyFile = key.replace(\"/\",\"_\")[:-3]\n",
    "    \n",
    "    try:\n",
    "        response = s3c.get_object(Bucket=b, Key=k)\n",
    "        print(\"CONTENT TYPE: \" + response['ContentType'])\n",
    "        \n",
    "        ## Add Function of your choice\n",
    "        ##############################\n",
    "        data = processData(Bucket, Key)\n",
    "        ##############################\n",
    "        s3r.Object('data-eng-project', 'stream/' + keyFile).put(Body = data )\n",
    "        \n",
    "        return Bucket, Key, response['ContentType']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Error getting object {} from bucket {}.'.format(key, bucket))\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon CouldWatch Dashboard!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/dash2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "import numpy as np\n",
    "import pyart.graph\n",
    "import tempfile\n",
    "import pyart.io\n",
    "import boto\n",
    "import geopy\n",
    "import math\n",
    "import re\n",
    "import csv\n",
    "from geopy.distance import VincentyDistance\n",
    "\n",
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from boto.s3.connection import S3Connection\n",
    "aws_access_key_id = \"AKIAJN3VR7WUHQ4DW57Q\"\n",
    "aws_secret_access_key = \"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\"\n",
    "s3conn = S3Connection(aws_access_key_id, aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generates a regular expression with which to grab the files we want from AWS\n",
    "\n",
    "def generate_regex(year=False,month=False,day=False,station=False):\n",
    "    y = str(year) if year else \"\\d*\"\n",
    "    m = str(month) if month else \"\\d*\"\n",
    "    d = str(day) if day else \"\\d*\"\n",
    "    s = station if station else \".*\"\n",
    "    return y+\"\\/\"+m+\"\\/\"+d+\"\\/\"+s+\".*\\.gz\"\n",
    "\n",
    "# Creates a short cut to limit the numebr of keys we need to search to get the files we want \n",
    "def generate_short_cut_path(year,month=False,day=False,station=False):\n",
    "    shortcutTemplate = str(year)\n",
    "    if month:\n",
    "        shortcutTemplate += \"/\" + str(month)\n",
    "        if day:\n",
    "            shortcutTemplate += \"/\" + str(day)\n",
    "            if station:\n",
    "                shortcutTemplate += \"/\" + station\n",
    "    return shortcutTemplate\n",
    "\n",
    "# Grab a list of files we want from the NEXRad data set\n",
    "def grab_list_of_files(year,month=False,day=False,station=False):\n",
    "    s3conn = S3Connection(aws_access_key_id, aws_secret_access_key)\n",
    "    bucket   = s3conn.get_bucket('noaa-nexrad-level2')\n",
    "    regex    = generate_regex(year,month,day,station)\n",
    "    shortcut = generate_short_cut_path(year,month,day,station)\n",
    "    print shortcut\n",
    "    print regex\n",
    "    keys = [key.key for key in bucket.list(shortcut) if re.match(regex,key.key)  ]\n",
    "\n",
    "    return keys\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use Boto to grab the file from s3 and load it in to pyart\n",
    "def grab_and_process_radar(key):\n",
    "    s3conn = S3Connection(aws_access_key_id, aws_secret_access_key)\n",
    "    bucket = s3conn.get_bucket('noaa-nexrad-level2')\n",
    "    s3key = bucket.get_key(key)\n",
    "    localfile = tempfile.NamedTemporaryFile()\n",
    "    s3key.get_contents_to_filename(\"data.gz\")\n",
    "    call([\"gunzip\", \"data.gz\"])\n",
    "    radar = pyart.io.read_nexrad_archive(\"data\")\n",
    "    return radar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_data(radar):\n",
    "    refl_grid = radar.get_field(0, 'reflectivity')\n",
    "    rhohv_grid = radar.get_field(0, 'cross_correlation_ratio')\n",
    "    zdr_grid = radar.get_field(0, 'differential_reflectivity')\n",
    "\n",
    "    # apply rudimentary quality control\n",
    "    reflow = np.less(refl_grid, 20)\n",
    "    zdrhigh = np.greater(np.abs(zdr_grid), 2.3)\n",
    "    rhohvlow = np.less(rhohv_grid, 0.95)\n",
    "    notweather = np.logical_or(reflow, np.logical_or(zdrhigh, rhohvlow))\n",
    "\n",
    "    qcrefl_grid = ma.masked_where(notweather, refl_grid)\n",
    "    qced = radar.extract_sweeps([0])\n",
    "    qced.add_field_like('reflectivity', 'reflectivityqc', qcrefl_grid)\n",
    "    return qced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def offset_by_meters(x,y,lat,lon):\n",
    "    if x==y==0:\n",
    "        return lat,lon\n",
    "    dist = math.sqrt(x*x+y*y)\n",
    "    bearing = math.atan2(y,x)\n",
    "\n",
    "    origin = geopy.Point(lat, lon)\n",
    "    destination = VincentyDistance(meters=dist).destination(origin, math.degrees(bearing))\n",
    "\n",
    "    lat2, lon2 = destination.latitude, destination.longitude    \n",
    "    return lat2,lon2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_as_csv(filename,data,level, append, extent=300, points=100):\n",
    "\n",
    "    grids = pyart.map.grid_from_radars(\n",
    "        (data,),\n",
    "        grid_shape=(11, points, points),\n",
    "        grid_limits= ((0, 11000), (-extent*1000.0, extent*1000.0), (-extent*1000.0, extent*1000.0)),\n",
    "        fields=['reflectivityqc'],\n",
    "        refl_field='reflectivityqc',\n",
    "        max_refl=100.)\n",
    "    center  = [grids.axes[\"lat\"][\"data\"][0], grids.axes[\"lon\"][\"data\"][0]]\n",
    "    date    = grids.axes['time'][\"units\"].replace( \"seconds since \",\"\")\n",
    "    print date\n",
    "    \n",
    "    ref = grids.fields[\"reflectivityqc\"][\"data\"][level]\n",
    "    \n",
    "    x_dists = grids.axes[\"x_disp\"][\"data\"]\n",
    "    y_dists = grids.axes[\"y_disp\"][\"data\"]\n",
    "    \n",
    "    data    = np.array(grids.fields[\"reflectivityqc\"][\"data\"][level])\n",
    "    \n",
    "    if append:\n",
    "        csvfile =  open(filename, 'ab')\n",
    "    else:\n",
    "        csvfile =  open(filename, 'wb')\n",
    "    writer = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    if not append:\n",
    "        writer.writerow([\"lat\", \"lon\", \"value\",\"date\"])\n",
    "    for (ix,iy), value in np.ndenumerate(data):\n",
    "        if value != -9999.0:\n",
    "            x = x_dists[ix]\n",
    "            y = y_dists[iy]\n",
    "            lat, lon = offset_by_meters(x,y,center[0],center[1])\n",
    "            writer.writerow([lat,lon,value,date])\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/07/03/KMHX\n",
      "2014\\/07\\/03\\/KMHX.*\\.gz\n",
      "got  254\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "#keys = grab_list_of_files(\"2015\", \"05\", \"15\", station=\"KVWX\")\n",
    "keys = grab_list_of_files(\"2014\", \"07\", \"03\", station=\"KMHX\")\n",
    "#keys = grab_list_of_files(\"2005\", \"08\", \"29\", station=\"KLIX\") # Hurricane Katrina 2005/08/29/\n",
    "print \"got \", len(keys)\n",
    "print len(keys[:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in keys[100:200]:\n",
    "    print \"doing file \", key\n",
    "\n",
    "    radar  = grab_and_process_radar(key)\n",
    "    print radar.get_field(0, 'cross_correlation_ratio') \n",
    "    filtered_data = filter_data(radar)\n",
    "    print filtered_data\n",
    "    append = (key != keys[0])\n",
    "    data = save_as_csv(\"result.csv\", filtered_data, 5 ,append)\n",
    "    plt.imshow(data)\n",
    "    call([\"rm\", \"data.gz\"])\n",
    "    call([\"rm\", \"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://marvinbertin.cartodb.com/viz/bff84faa-e3fa-11e5-aa36-0e5db1731f59/embed_map\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x111dd6cd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame('https://marvinbertin.cartodb.com/viz/bff84faa-e3fa-11e5-aa36-0e5db1731f59/embed_map', width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Version 2.0\n",
    "\n",
    "- Include forcasting analytics\n",
    "- Port the rest of the project into a AWS Lambda framework\n",
    "- Hadoop computations into Spark or Flink\n",
    "- Create a web interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
